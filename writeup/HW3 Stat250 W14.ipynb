{
 "metadata": {
  "name": "",
  "signature": "sha256:41ee7c32e0aebe8f95809e927bc589c7c896f443bb0639837d01b907078291e9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Author: Karen Ng <karenyng@ucdavis.edu> \n",
      "\n",
      "<a href=\"https://github.com/karenyng/HW3_Stat250_W14\" target=\"_blank\">Github repository for this HW</a>\n",
      "\n",
      "Written with an IPython notebook v. 2.0.0-dev"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autosave 60\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Background of <a href =\"http://eeyore.ucdavis.edu/stat250/Homeworks/hw3.html\" target=\"_blank\">assignment</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We explore <a href=\"https://web.archive.org/web/20130609062934/http://stackoverflow.com/help/closed-questions\" target=\"_blank\">Stack Overflow</a> questions that should be closed.\n",
      "This classification problem comes from a \n",
      "<a href=\"https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow\"  target=\"_blank\">Kaggle competition</a>.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Content "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This approximately corresponds to the workflow that I imagine would be ideal but I do not have time to do everything.   \n",
      "So I use the following keys to indicate what I have done.\n",
      "\n",
      ". - not done    \n",
      "0 - half done     \n",
      "x - I consider it done ....     \n",
      "empty - it is a possibility that it might get done     \n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[x] [Get data to remote machine](#Getting-the-data-using-the-cookie-and-curl)\n",
      "    * small training set \n",
      "    * bigger 6GB full data set \n",
      "    * the XML files 12 GBs?\n",
      "   \n",
      "[0] [Data exploration](#Data-Exploration)          \n",
      "       * [0] examine nature / relationship between different variables     \n",
      "        [ ] examine how actual content of questions helps ....     \n",
      "        [x] convert markdown to pure text      \n",
      "        [x] do NLP for the content of the questions       \n",
      "        [0] create suitable new variables       \n",
      "        [0] verify data integrity after transformation / reduction      \n",
      "        [0] make simplifying assumptions \n",
      "        [0] MAYBE remove low signal-to-noise data points / outliers\n",
      "        [ ]massage data to look like the form that the stat / ML functions want\n",
      "  \n",
      "* [Background of Stat/ML techniques: Random Forest](#Random-Forest-from-scikit-learn)\n",
      "* [Analysis](#Analysis)      \n",
      "        [0] get a 2-case classification done (open / close) just using the user info to get intuition \n",
      "            * can actually use logistical regression \n",
      "            * or SVM\n",
      "        [0] get 5-case classification - the correct classification rate is ~78%... I do not think this is done quite correctly ...\n",
      "[ ] try to use more than one technique to verify the results are not insane\n",
      "\n",
      "* [Estimate and tweak performance](#Performance)\n",
      "          \n",
      "        [0] look at point percent misclassification \n",
      "        [?] look at the oob score estimate - something went wrong with this, it \"worked\" at some point\n",
      "        [?] do cross validation  \n",
      "        [ ] look at confusion matrix\n",
      "        [.] look at variable importance - somehow the default outputs seem funky\n",
      "        [ ] rethink strategy\n",
      "    * maybe redo RF again after tuning the input parameters based on performance\n",
      "* [Code](#Code) \n",
      "    * Dependencies \n",
      "    * Actual code"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Personal goals:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* learn how to use existing statistical packages / machine learning functions \n",
      "* learn the underlying considerations when preparing the data for those functions \n",
      "* learn the workflow of data analysis "
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data sets used"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Getting the data using the cookie and curl"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Google Chrome also shows content of cookie in the developer tool but the attributes seem to be chopped up and cannot be easily cut and paste to be used with curl. \n",
      "\n",
      "So I had to use my second favorite browser firefox to extract the cookie."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1) train.csv - training data "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    curl -L --cookie \"MYFIREFOXCOOKIE\" https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow/download/train.7z > train.7z\n",
      "    \n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2) entire data dump "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    curl -L --cookie \"MYFIREFOXCOOKIE\" https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow/download/2012-07%20Stack%20Overflow.7z > 2012-07-Stack-Overflow.7z"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How to get all the csv files from the Kaggle data website:\n",
      "* there must be something in the XML package (or other packages) that Duncan wrote that can get all the links, by searching for the attribute \"a href\"\n",
      "And we can use RCurl within R to download the csv files \n",
      "* download html code of the website, use sed / awk to filter out the links which are after \"a href\" and inside quotes, then use Curl in the shell\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Choice of programming language / packages"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It's hard to decide because R seems like a really good choice but I am also very slow when using R. I want to use python since I want to focus on learning about the statistics / ML method than learning about programming / a programming language."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "<a href=\"http://nbviewer.ipython.org/github/karenyng/HW3_Stat250_W14/blob/master/writeup/Data%20exploration%20and%20preprocessing.ipynb?create=1\" target=\"_blank\">Data exploration</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Click the link above to see another IPython notebook with other detailed code, plots and discussion.\n",
      "Here I will just put the most important findings."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data Exploration"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Detailed code is <a href=\"http://nbviewer.ipython.org/github/karenyng/HW3_Stat250_W14/blob/master/writeup/Data%20exploration%20and%20preprocessing.ipynb?create=1\">here </a> "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Training data - train.csv"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> size: ~3.5 GB \n",
      "\n",
      "> no. of observations in training data = 3.37 M\n",
      "\n",
      "> no. of open questions =  3.30 M, 97.92% of total observations \n",
      "\n",
      "> no. of closed questions = 70.1 K, 2.08% of total observations \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given the number of fields (variables) is ~10 << 70.1K ,\n",
      "we should feel free to create more variables to summarize the context of the questions. \n",
      "\n",
      "Note the percentage break down of train.csv is not what's claimed in the SO website. A further breakdown of the reasons reveal:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<table>\n",
      "<tr><td>Reason for closing question</td><td>% out of all closed questions</td>\n",
      "<tr>\n",
      "<td> too localized </td><td>8.78% </td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td> not constructive </td><td>22.33% </td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td> off topic </td><td>24.99% </td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td> not a real question </td><td>43.90% </td>\n",
      "</tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* not sure if it's ok to use these numbers as prior in case we want to use naive Bayes but may not matter for other stat / ML techniques\n",
      "* if there is only ~9% of the questions being in the \"too localized\" category, it might not be easy to train it "
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data reduction and preprocessing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Duncan gave a <a href=\"https://github.com/karenyng/stat250/blob/master/notes/15.md\" target=\"_blank\">good lecture</a> the other day about how to create variables out of the content of the questions, i.e. preprocessing data. That got me wondering if all of the given variables are actually relevant..... \n",
      "\n",
      "And I came across <a href=\"http://www.kdnuggets.com/2014/03/data-mining-do-and-dont.html\" target=\"_blank\">this article</a> about data-mining do-and-don't which emphasizes data ETL, preparation etc.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Stripping markdown from text"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I actually installed the javascript engine node.js on my remote machines for use. They are slightly awkward and I found that Python has its own modules for converting markdown to plain text. \n",
      "\n",
      "The use is a little tricky since the modules seem to like utf-8 as the encoding but the default python's string encoding is ascii.\n",
      "\n",
      "* convert markdown to html using the markdown module\n",
      "* use default functions from nltk to strip the html code \n",
      "* do stemming and other precprocessing steps using nltk"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Given variables"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* PostCreationDate\n",
      "* OwnerUserId\n",
      "* OwnerCreationDate\n",
      "* ReputationAtPostCreation\n",
      "* OwnerUndeletedAnswerCountAtPostTime\n",
      "* Title\n",
      "* BodyMarkdown\n",
      "* Tag1\n",
      "* Tag2\n",
      "* Tag3\n",
      "* Tag4\n",
      "* Tag5\n",
      "\n",
      "It seems likely that Tag 1-5 should be related to the actual content of the of the question and should be analyzed together. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Create new variables "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To know what new variables would be helpful involves guesswork and is not easy to do well. See the data exploration ipynb for more discussion."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Random Forest from scikit learn"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The documentation from Rpart is very nice and I am very tempted but I do not want to switch language in the middle of the analysis! Will use it next time!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "characteristics "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Snag: \n",
      "When we add new data / variables, we have to rebuild our trees...\n",
      "\n",
      "* can use the out of bag data points for doing cross validation, it is easy to show that $N_{oob} \\approx N_{total} e^{-1}$ data points will not be used to build the trees\n",
      "\n",
      "\n",
      "* ranked as one of the best algorithms in Kaggle competitions etc.\n",
      "\n",
      "* Summary from Elements of statistical learning regarding the use of random forest:\n",
      "\n",
      "    * select $m$ out of $p$ variables at each split, \n",
      "    * it recommends using $m = \\sqrt{p} $ and the minimum node size is $1$ for classification \n",
      "    * but we need to tune $m$ after first trying the values of $m$ out \n",
      "    * when $m$ is small and the fraction of relevant variables is small, then RF may perform poorly\n",
      "    * when the # of relevant variables is sufficient, RF will perform more robustly - so the creation of relevant variables is important.......unless we don't care and just want to use statistical techniques for the sake of using statistical techniques."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Usage"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are a bunch of parameters that I should set / think about: "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* max_features = this is tree specific but since we know the features we want to test so we set this \n",
      "    * 2 for the testing purpose to see how well it does for just classifying open and closed cases\n",
      "    * 5 for the real deal\n",
      "    \n",
      "* criterion = \"gini\" cofficient is the default criteria for splitting and I think it's fine.\n",
      "    \n",
      "* max_depth = \n",
      "\n",
      "* bootstrap = Yes! Not sure why there 's a choice.....\n",
      "\n",
      "* oob_score = True ! please do the entire homework for me.\n",
      "\n",
      "* n_jobs = 4 \n",
      "    * very nice that the developers had parallelization in mind when designing the package\n",
      "\n",
      "* verbose = True \n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Results "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "What are good predictors? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat ../code/RF_2014-03-07\\ 01\\:52.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "----------training data percent breakdown ----------\r\n",
        "Closed percent:  50.0%\r\n",
        "not constructive percent:  11.1633112809%\r\n",
        "off topic percent:  12.4971483974%\r\n",
        "not a real question percent:  21.9494981179%\r\n",
        "too localized percent:  4.39004220372%\r\n",
        "Number of training obs = 140272\r\n",
        "----------test data percent breakdown ----------\r\n",
        "Number of testing obs = 3370528\r\n",
        "Closed percent:  2.08086092149%\r\n",
        "not constructive percent:  0.46458596398%\r\n",
        "off topic percent:  0.520096554605%\r\n",
        "not a real question percent:  0.9134770576%\r\n",
        "too localized percent:  0.182701345309%\r\n",
        "------------------------------------------------\r\n",
        "--------input params----------------------------\r\n",
        "criterion for split = gini\r\n",
        "max_features to be used for split = sqrt\r\n",
        "binary classification or not = False\r\n",
        "no of trees = 280\r\n",
        "------------------------------------------------\r\n",
        "OOB score : 0.0\r\n",
        "Features summary :\r\n",
        "['postOwnerTimeDiff', 'ReputationAtPostCreation', 'OwnerUndeletedAnswerCountAtPostTime', 'OwnerUserId', 'PostId']\r\n",
        "[ 0.1676744   0.15066486  0.07623801  0.30232671  0.30309602]\r\n",
        "mean accuracy : 0.784443564925\r\n",
        "Overall PCC : 78.4443564925%\r\n",
        "not constructive PCC : 100.0%\r\n",
        "off topic PCC : 100.0%\r\n",
        "not a real question PCC : 100.0%\r\n",
        "too localized PCC : 100.0%\r\n",
        "open PCC : 77.9862816296%\r\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "looking at the \"feature importance score\" from the RF output, we have:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* UserID (this is very surprising - will have to plot the UserID and see how it clusters for different categories to understand why this is important)\n",
      "* PostID \n",
      "* date differences between the owner and the post creation date \n",
      "    * i.e. how experienced the owner is \n",
      "* Owner reputation \n",
      "* OwnerUndeletedAnswerCountAtPostTime"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Importance of variables given by the RF function"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not really sure if the scores really correspond to the feature importance. The documentation is not very clear"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Cross validation "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is a function in scikit learn for preserving the percentage of the categories when subsetting the data for cross validation.\n",
      "Don't have time to do this."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Performance"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Misclassification rate (or percent correct classification PCC) "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* not great especially for the open case. I should have spent more time on doing the statistics haha."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Code"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Dependencies "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* pandas \n",
      "* nltk\n",
      "* markdown \n",
      "* matplotlib\n",
      "* scikit learn"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Actual code "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "there are other variants of the same code but I will just show one"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sed -n '1, 101p' ../code/hw3.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#======================================================================\r\n",
        "# Author: Karen Ng <karenyng@ucdavis.edu>\r\n",
        "# Date: 03/16/2014\r\n",
        "# Winter 14 Stat 250 HW 3\r\n",
        "# \"prototype\" code for classifying SO questions\r\n",
        "#======================================================================\r\n",
        "from __future__ import division\r\n",
        "import sys\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "\r\n",
        "# homebrewed module from path\r\n",
        "sys.path.append('../writeup/')\r\n",
        "import helper\r\n",
        "import datetime\r\n",
        "\r\n",
        "#-----initialize values------------------------------------------------\r\n",
        "train_file = \"../data/train-sample-datediff.csv\"\r\n",
        "test_file = \"../data/train-datediff.csv\"\r\n",
        "date1 = \"OwnerCreationDate\"\r\n",
        "date2 = \"PostCreationDate\"\r\n",
        "dateDiff = \"postOwnerTimeDiff\"\r\n",
        "output_file = \"RF_\" + str(datetime.datetime.now())[:16] + \".txt\"\r\n",
        "\r\n",
        "criterion = 'gini'\r\n",
        "max_features = None\r\n",
        "binaryClass = False\r\n",
        "\r\n",
        "# initialize list of strings of variables to be used for RF\r\n",
        "var = [dateDiff,\r\n",
        "       \"ReputationAtPostCreation\",\r\n",
        "       \"OwnerUndeletedAnswerCountAtPostTime\",\r\n",
        "       \"OwnerUserId\",\r\n",
        "       \"PostId\"]\r\n",
        "status = \\\r\n",
        "    [\"not constructive\", \"off topic\", \"not a real question\", \"too localized\"]\r\n",
        "\r\n",
        "#----------------------------------------------------------------------\r\n",
        "# read in and preprocess data\r\n",
        "train = pd.read_csv(train_file)\r\n",
        "test = pd.read_csv(test_file, nrows=train.shape[0])\r\n",
        "#train = \\\r\n",
        "#    helper.get_timeStamp_and_compute_date_diff(train, date1, date2, dateDiff)\r\n",
        "#test = \\\r\n",
        "#    helper.get_timeStamp_and_compute_date_diff(test, date1, date2, dateDiff)\r\n",
        "\r\n",
        "if binaryClass is True:\r\n",
        "    train[\"binaryStatus\"] = pd.DataFrame(np.zeros(train.shape[0]))\r\n",
        "    train[\"binaryStatus\"][train[\"OpenStatus\"] == \"open\"] = 1\r\n",
        "\r\n",
        "    test[\"binaryStatus\"] = pd.DataFrame(np.zeros(test.shape[0]))\r\n",
        "    test[\"binaryStatus\"][test[\"OpenStatus\"] == \"open\"] = 1\r\n",
        "\r\n",
        "# it does not matter how the population of the training set look like\r\n",
        "# for a random forest but it is good to examine it\r\n",
        "f = open(output_file, 'w')\r\n",
        "f.write(\"----------training data percent breakdown ----------\\n\")\r\n",
        "helper.question_percent_breakdown(train, status, f)\r\n",
        "f.write(\"Number of training obs = {0}\\n\".format(train.shape[0]))\r\n",
        "f.write(\"----------test data percent breakdown ----------\\n\")\r\n",
        "f.write(\"Number of testing obs = {0}\\n\".format(test.shape[0]))\r\n",
        "helper.question_percent_breakdown(test, status, f)\r\n",
        "f.write(\"------------------------------------------------\\n\")\r\n",
        "f.write(\"--------input params----------------------------\\n\")\r\n",
        "f.write(\"criterion for split = {0}\\n\".format(criterion))\r\n",
        "f.write(\"max_features to be used for split = {0}\\n\".format(max_features))\r\n",
        "f.write(\"binary classification or not = {0}\\n\".format(binaryClass))\r\n",
        "\r\n",
        "# ------ initialize my random forest--------------------------------------\r\n",
        "# some of the following input parameters for the RF might be ridiculous\r\n",
        "# I don't know how many trees to use so I try to build many\r\n",
        "n_estimators = int(train.shape[0] / 1e2)\r\n",
        "f.write(\"no of trees = {0}\\n\".format(n_estimators))\r\n",
        "f.write(\"------------------------------------------------\\n\")\r\n",
        "print \"No. of trees to be built = {0}\\n\".format(n_estimators)\r\n",
        "\r\n",
        "\r\n",
        "myForest = \\\r\n",
        "    RandomForestClassifier(n_estimators=n_estimators,\r\n",
        "                           criterion=criterion,\r\n",
        "                           max_features=max_features,  # features = variables\r\n",
        "                           oob_score=True,\r\n",
        "                           bootstrap=True,\r\n",
        "                           n_jobs=4,\r\n",
        "                           verbose=1)\r\n",
        "\r\n",
        "# ------data to be used for building the tree----------------\r\n",
        "# subset the training dataframe so that only specified variables\r\n",
        "# get passed as input for building the forest\r\n",
        "X = train[var]\r\n",
        "# the random forest algorithm only likes integer that indicate categories\r\n",
        "if binaryClass is True:\r\n",
        "    y = train[\"binaryStatus\"]\r\n",
        "else:\r\n",
        "    y = train[\"OpenStatus\"].apply(hash)\r\n",
        "forest = myForest.fit(X, y)\r\n",
        "\r\n",
        "#--------prediction time-------------------------------------\r\n",
        "test[\"RFclass\"] = pd.DataFrame(forest.predict(test[var]))\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sed -n '102, 140p' ../code/hw3.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "#-------performance statistics ------------------------------\r\n",
        "# compute if the prediction is correct or not\r\n",
        "# if the two predicted class, the corresponding entry of \"result\" would be 1\r\n",
        "if binaryClass is True:\r\n",
        "    test[\"result\"] = \\\r\n",
        "        pd.DataFrame(test[\"RFclass\"] == test[\"binaryStatus\"])\r\n",
        "else:\r\n",
        "    test[\"result\"] = \\\r\n",
        "        pd.DataFrame(test[\"RFclass\"] == test[\"OpenStatus\"].apply(hash))\r\n",
        "\r\n",
        "overallPCC = np.sum(test[\"result\"]) / test.shape[0] * 100\r\n",
        "\r\n",
        "# PCC for different status\r\n",
        "allstatus = status + [\"open\"]\r\n",
        "PCC = []\r\n",
        "for status in allstatus:\r\n",
        "    if binaryClass is not True:\r\n",
        "        mask = test[\"OpenStatus\"] == status\r\n",
        "    else:\r\n",
        "        mask = test[\"binaryStatus\"] == helper.binaryStatusOrNot(status)\r\n",
        "    PCC.append(np.sum(test[mask][\"result\"]) / test[mask].shape[0] * 100)\r\n",
        "\r\n",
        "#-------------write out results -----------------------------\r\n",
        "f.write(\"OOB score : {0}\\n\".format(forest.oob_score_))\r\n",
        "f.write(\"Features summary :\\n\")\r\n",
        "f.write(\"{0}\\n\".format(var))\r\n",
        "f.write(\"{0}\\n\".format(forest.feature_importances_))\r\n",
        "if binaryClass is True:\r\n",
        "    f.write(\"mean accuracy : {0}\\n\".format(\r\n",
        "        forest.score(test[var], test['binaryStatus'])))\r\n",
        "else:\r\n",
        "    f.write(\"mean accuracy : {0}\\n\".format(\r\n",
        "        forest.score(test[var], test['OpenStatus'].apply(hash))))\r\n",
        "\r\n",
        "f.write(\"Overall PCC : {0}%\\n\".format(overallPCC))\r\n",
        "for i in range(len(allstatus)):\r\n",
        "    f.write(allstatus[i] + \" PCC : {0}%\\n\".format(PCC[i]))\r\n",
        "f.close()\r\n"
       ]
      }
     ],
     "prompt_number": 3
    }
   ],
   "metadata": {}
  }
 ]
}